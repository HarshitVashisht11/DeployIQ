# DeployIQ

DeployIQ is a powerful and easy-to-use application that simplifies the deployment of open-source LLMs like **Llama 3, Mistral, and Falcon**. Users can select a model from the frontend, and DeployIQ will automatically handle hosting and API key generation.

## Key Features

- **Deploys Open-Source LLMs**: Supports **Llama 3 and Claude**.
- **Automated Hosting**: Models are hosted automatically upon selection.
- **Secure API Deployment**: REST/gRPC with token-based authentication.
- **Web-Based Frontend**: Next.js UI for managing deployments.
- **Model Hosting**: Llama models do not provide an API key, but DeployIQ generates one via metadata hosting on **AWS or local storage**.
- **Dashboard**: Users can see all deployed models along with their API keys and API URLs generated by DeployIQ.

---

## Tech Stack

- **Frontend**: Next.js (React-based UI)
- **Backend**: Node.js, Prisma for details see readme file in backend for detailed explanation of routes and all functionalites.
- **Database**: PostgreSQL (NeonDB)

---

## Installation & Setup

### Prerequisites

- **Node.js & npm** (for frontend & backend)
- **Docker** (for local deployment)

### Step 1: Clone the Repository

```sh
git clone https://github.com/your-repo/DeployIQ.git
cd DeployIQ
```

### Step 2: Install Dependencies

#### Backend (Node.js)

```sh
cd backend
npm install
```

#### Frontend (Next.js)

```sh
cd ../frontend
npm install
```

### Step 3: Create a `.env` File in `backend` Directory

Create a `.env` file inside the `backend` folder with the following content:

```env
DATABASE_URL="your_postgresql_connection_string"
JWT_SECRET="your_jwt_secret_key"
PORT="5000"
AWS_REGION="your_aws_region"
AWS_ACCESS_KEY_ID="your_aws_access_key"
AWS_SECRET_ACCESS_KEY="your_aws_secret_key"
STRIPE_SECRET_KEY="your_stripe_secret_key"
API_BASE_URL="http://localhost:5000"
```

### Step 4: Run the Project

#### Start Backend

```sh
cd backend
npm i
npm run dev
```

#### Start Frontend

```sh
cd ../frontend
npm i
npm run dev
```

---

## How It Works

1. **Landing Page**: Users arrive at the homepage with an overview of DeployIQ.
2. **Signup/Login**: New users sign up or log in to access the dashboard.
3. **Choose Model**: Users select an LLM (**Llama 3** or **Claude** for now).
4. **Deployment**:
   - **Llama models do not provide API keys**, but DeployIQ generates one by hosting metadata on **AWS or local storage**.
   - Deployment is initiated automatically based on the chosen model.
5. **Dashboard**:
   - Users can view all deployed models along with their API keys and API URLs.
   - API credentials are generated automatically and displayed in the dashboard.

---

## API Endpoints

### Authentication

| Method | Endpoint       | Description                  |
| ------ | -------------- | ---------------------------- |
| POST   | `/auth/signup` | Create a new user            |
| POST   | `/auth/login`  | Authenticate and get a token |

### Model Deployment

| Method | Endpoint     | Description             |
| ------ | ------------ | ----------------------- |
| POST   | `/deploy`    | Deploy an LLM           |
| GET    | `/getmodels` | Get available models    |
| POST   | `/invoke`    | Invoke a deployed model |

---

## Future Enhancements

- **Web Dashboard Enhancements** for better model management.
- **On-the-fly Model Fine-Tuning**.
- **Auto-Scaling Improvements** based on real-time demand.

---
## License

MIT License

---

## Contact

For support, open an issue on GitHub.

---

ðŸš€ **DeployIQ - Deploy LLMs seamlessly on cloud and local environments!**

